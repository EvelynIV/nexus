from typing import Iterable, Optional
import asyncio
import logging
from dataclasses import dataclass, field
from typing import TYPE_CHECKING

from openai.types import realtime
from openai.types.chat import ChatCompletionChunk

from nexus.infrastructure.asr import TranscriptionResult
from nexus.application.realtime.protocol.ids import event_id, item_id
from nexus.application.realtime.emitters.response_contexts import (
    AudioResponseContext,
    FunctionCallResponseContext,
    McpCallResponseContext,
    TextResponseContext,
)

if TYPE_CHECKING:
    from nexus.domain.realtime import RealtimeSessionState
    from nexus.infrastructure.tts import Inferencer as TTSInferencer

logger = logging.getLogger(__name__)


def get_usage_tokens(transcript: str):
    """è®¡ç®—è½¬å½•æ–‡æœ¬çš„ä½¿ç”¨ token æ•°"""
    # ç®€å•æŒ‰ç©ºæ ¼åˆ†è¯è®¡æ•°ï¼Œå®é™…å¯æ ¹æ®å…·ä½“æ¨¡å‹çš„ tokenizer å®ç°æ›´ç²¾ç¡®çš„è®¡æ•°
    tokens = len(transcript.strip().split())
    usage = realtime.conversation_item_input_audio_transcription_completed_event.UsageTranscriptTextUsageTokens(
        total_tokens=tokens,
        output_tokens=0,
        input_tokens=tokens,
        type="tokens",
    )
    return usage


# ---------------------------------------------------------------------------
# TranscriptionStreamTracker â€“ è¿½è¸ªæµå¼è½¬å†™çŠ¶æ€ï¼Œä»ç´¯ç§¯å­—ç¬¦ä¸²ä¸­æå–å¢é‡ delta
# ---------------------------------------------------------------------------

@dataclass
class TranscriptionStreamTracker:
    """Tracks incremental transcription state across interim ASR results.

    ASR å¼•æ“æ¯æ¬¡è¿”å›ç´¯ç§¯åçš„å®Œæ•´å­—ç¬¦ä¸²ï¼ˆå¦‚ "ä»Šå¤©çš„" â†’ "ä»Šå¤©çš„å¤©æ°”çœŸ" â†’ "ä»Šå¤©çš„å¤©æ°”çœŸå¥½"ï¼‰ï¼Œ
    æœ¬ç±»è´Ÿè´£ä»ä¸­æå–çœŸæ­£çš„å¢é‡ deltaï¼ˆ"ä»Šå¤©çš„" / "å¤©æ°”çœŸ" / "å¥½"ï¼‰ï¼Œ
    ä»¥ç¬¦åˆ OpenAI Realtime API çš„ conversation.item.input_audio_transcription.delta è¯­ä¹‰ã€‚
    """

    _previous_transcript: str = field(default="", init=False)
    _item_id: Optional[str] = field(default=None, init=False)
    _speech_started_sent: bool = field(default=False, init=False)

    @property
    def item_id(self) -> str:
        """å½“å‰è¯­å¥çš„ item_idï¼Œé¦–æ¬¡è®¿é—®æ—¶è‡ªåŠ¨åˆ†é…ã€‚"""
        if self._item_id is None:
            self._item_id = item_id()
        return self._item_id

    @property
    def speech_started_sent(self) -> bool:
        return self._speech_started_sent

    def mark_speech_started(self) -> None:
        self._speech_started_sent = True

    def compute_delta(self, current_transcript: str) -> str:
        """Compute the incremental delta from the previous transcript.

        If *current_transcript* starts with the previous accumulated string,
        return the new suffix.  Otherwise (ASR corrected earlier text) fall
        back to returning the full *current_transcript* and log a warning.
        """
        prev = self._previous_transcript
        if current_transcript.startswith(prev):
            delta = current_transcript[len(prev):]
        else:
            # ASR çº æ­£äº†ä¹‹å‰çš„è¯†åˆ«ç»“æœï¼Œå›é€€åˆ°å®Œæ•´æ–‡æœ¬
            logger.warning(
                "ASR transcript not a prefix extension (prev=%r, cur=%r); "
                "sending full transcript as delta",
                prev,
                current_transcript,
            )
            delta = current_transcript
        self._previous_transcript = current_transcript
        return delta

    def reset(self) -> None:
        """Reset state after a final result, ready for the next utterance."""
        self._previous_transcript = ""
        self._item_id = None
        self._speech_started_sent = False


# ---------------------------------------------------------------------------
# send_transcribe_interim â€“ å¤„ç† is_final=False çš„ä¸­é—´ ASR ç»“æœ
# ---------------------------------------------------------------------------

async def send_transcribe_interim(
    session: "RealtimeSessionState",
    transcription_result: TranscriptionResult,
    tracker: TranscriptionStreamTracker,
) -> None:
    """Send streaming delta events for an interim (non-final) ASR result."""

    # é¦–æ¬¡æ”¶åˆ° interim ç»“æœæ—¶ç«‹å³å‘é€ speech_startedï¼ˆä½å»¶è¿Ÿï¼‰
    if not tracker.speech_started_sent:
        if transcription_result.words:
            _, start_time, _ = transcription_result.words[0]
        else:
            start_time = 0.0
        vad_start_event = realtime.InputAudioBufferSpeechStartedEvent(
            audio_start_ms=int(start_time * 1000),
            type="input_audio_buffer.speech_started",
            event_id=event_id(),
            item_id=tracker.item_id,
        )
        await session.send_event(vad_start_event)
        tracker.mark_speech_started()

    # è®¡ç®—å¢é‡ delta
    delta = tracker.compute_delta(transcription_result.transcript)
    if not delta:
        return

    delta_event = realtime.ConversationItemInputAudioTranscriptionDeltaEvent(
        event_id=event_id(),
        item_id=tracker.item_id,
        type="conversation.item.input_audio_transcription.delta",
        content_index=0,
        delta=delta,
    )
    await session.send_event(delta_event)
    logger.debug("Sent interim delta: item_id=%s, delta=%r", tracker.item_id, delta)


# ---------------------------------------------------------------------------
# send_transcribe_response â€“ å¤„ç† is_final=True çš„æœ€ç»ˆ ASR ç»“æœï¼ˆé‡æ„åï¼‰
# ---------------------------------------------------------------------------

async def send_transcribe_response(
    session: "RealtimeSessionState",
    transcription_result: TranscriptionResult,
    tracker: Optional[TranscriptionStreamTracker] = None,
):
    """Complete the transcription event sequence for a final ASR result.

    When *tracker* is provided the function cooperates with prior interim
    deltas: it reuses the same ``item_id``, skips ``speech_started`` if
    already sent, and only emits the remaining delta.

    When *tracker* is ``None`` (backward-compat / non-interim mode) the
    function behaves like the original â€“ sends the full transcript in a
    single delta event.
    """
    is_final = transcription_result.is_final
    if not is_final:
        logger.warning(
            "send_transcribe_response called with non-final result",
        )
        return

    transcript = transcription_result.transcript

    # Determine item_id â€“ reuse from tracker if available
    if tracker is not None:
        response_item_id = tracker.item_id
    else:
        response_item_id = item_id()

    if transcription_result.words:
        _, start_time, end_time = transcription_result.words[0]
    else:
        start_time = end_time = 0.0

    # speech_started â€“ only send if not already sent by interim handler
    if tracker is None or not tracker.speech_started_sent:
        vad_start_event = realtime.InputAudioBufferSpeechStartedEvent(
            audio_start_ms=int(start_time * 1000),
            type="input_audio_buffer.speech_started",
            event_id=event_id(),
            item_id=response_item_id,
        )
        await session.send_event(vad_start_event)

    # speech_stopped
    vad_stop_event = realtime.InputAudioBufferSpeechStoppedEvent(
        audio_end_ms=int(end_time * 1000),
        type="input_audio_buffer.speech_stopped",
        event_id=event_id(),
        item_id=response_item_id,
    )
    await session.send_event(vad_stop_event)

    # committed
    committed_event = realtime.InputAudioBufferCommittedEvent(
        event_id=event_id(),
        item_id=response_item_id,
        type="input_audio_buffer.committed",
    )
    await session.send_event(committed_event)

    # Final delta â€“ send remaining increment (or full transcript in legacy mode)
    if tracker is not None:
        delta = tracker.compute_delta(transcript)
    else:
        delta = transcript
    if delta:
        delta_event = realtime.ConversationItemInputAudioTranscriptionDeltaEvent(
            event_id=event_id(),
            item_id=response_item_id,
            type="conversation.item.input_audio_transcription.delta",
            content_index=0,
            delta=delta,
        )
        await session.send_event(delta_event)

    # completed
    completed_event = realtime.ConversationItemInputAudioTranscriptionCompletedEvent(
        content_index=0,
        event_id=event_id(),
        item_id=response_item_id,
        transcript=transcript,
        type="conversation.item.input_audio_transcription.completed",
        usage=get_usage_tokens(transcript),
    )
    await session.send_event(completed_event)

    item = realtime.RealtimeConversationItemUserMessage(
        content=[
            realtime.realtime_conversation_item_user_message.Content(type="input_audio")
        ],
        role="user",
        type="message",
        id=response_item_id,
        object=None,
        status="completed",
    )
    conversation_add_event = realtime.ConversationItemAdded(
        event_id=event_id(), item=item, type="conversation.item.added"
    )
    await session.send_event(conversation_add_event)
    conversation_done_event = realtime.ConversationItemDone(
        event_id=event_id(), item=item, type="conversation.item.done"
    )
    await session.send_event(conversation_done_event)

    logger.info("Sent transcription response: item_id=%s, is_final=%s", response_item_id, is_final)

    # Reset tracker for the next utterance
    if tracker is not None:
        tracker.reset()


@dataclass
class ToolCallInfo:
    """å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    call_id: str
    name: str
    arguments: str
    is_mcp: bool = False  # æ˜¯å¦ä¸º MCP å·¥å…·è°ƒç”¨
    server_label: Optional[str] = None  # MCP æœåŠ¡å™¨æ ‡ç­¾
    mcp_ctx: Optional["McpCallResponseContext"] = None  # MCP ä¸Šä¸‹æ–‡ï¼ˆç”¨äºåç»­äº‹ä»¶å‘é€ï¼‰


@dataclass 
class ChatStreamResult:
    """èŠå¤©æµå¼å“åº”ç»“æœ"""
    content: str = ""
    tool_call: Optional[ToolCallInfo] = None
    was_cancelled: bool = False  # æ˜¯å¦è¢«æ‰“æ–­
    
    @property
    def has_tool_call(self) -> bool:
        return self.tool_call is not None
    
    @property
    def has_mcp_call(self) -> bool:
        return self.tool_call is not None and self.tool_call.is_mcp


def _modalities_or_default(modalities: Optional[list[str]]) -> list[str]:
    return list(modalities) if modalities else ["text"]


def _is_audio_mode(modalities: list[str]) -> bool:
    return "audio" in modalities


async def process_chat_stream(
    session: "RealtimeSessionState",
    chat_stream: Iterable[ChatCompletionChunk],
    *,
    modalities: Optional[list[str]] = None,
    tts_inferencer: Optional["TTSInferencer"] = None,
    audio_output_format_type: str = "audio/pcm",
    audio_output_voice: str = "alloy",
    audio_output_speed: float = 1.0,
) -> ChatStreamResult:
    """
    å¤„ç† chat æµå¼å“åº”ï¼ŒåŒæ—¶æµå¼å‘é€æ–‡æœ¬ç»™å®¢æˆ·ç«¯ã€‚
    
    æ­¤å‡½æ•°ä¼šç«‹å³å°†æ–‡æœ¬ delta å‘é€ç»™å®¢æˆ·ç«¯ï¼Œ
    å®ç°çœŸæ­£çš„æµå¼å“åº”ï¼Œé™ä½é¦–å­—å»¶è¿Ÿã€‚
    
    è¿”å› ChatStreamResultï¼ŒåŒ…å«å®Œæ•´æ–‡æœ¬å†…å®¹æˆ–å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚
    
    äº‹ä»¶æ—¶åºï¼ˆä¸ OpenAI å®˜æ–¹å¯¹é½ï¼‰ï¼š
    
    æ–‡æœ¬å“åº”ï¼š
    1. ResponseCreatedEvent
    2. ResponseOutputItemAddedEvent
    3. ConversationItemAdded
    4. ResponseContentPartAddedEvent
    5. ResponseOutputTextDeltaEvent (å¤šä¸ª)
    6. ResponseOutputTextDoneEvent
    7. ResponseContentPartDoneEvent
    8. ResponseOutputItemDoneEvent
    9. ConversationItemDone
    10. ResponseDoneEvent
    
    å·¥å…·è°ƒç”¨ï¼š
    1. ResponseCreatedEvent
    2. ResponseOutputItemAddedEvent  
    3. ConversationItemAdded
    4. ResponseFunctionCallArgumentsDeltaEvent (å¤šä¸ª)
    5. ResponseFunctionCallArgumentsDoneEvent
    6. ConversationItemDone
    7. ResponseOutputItemDoneEvent
    8. ResponseDoneEvent
    """
    active_modalities = _modalities_or_default(modalities)
    audio_mode = _is_audio_mode(active_modalities)

    result = ChatStreamResult()
    text_ctx: Optional[TextResponseContext] = None
    audio_ctx: Optional[AudioResponseContext] = None
    func_ctx: Optional[FunctionCallResponseContext] = None
    mcp_ctx: Optional[McpCallResponseContext] = None
    
    # ç”¨äºç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°
    tool_name: Optional[str] = None
    tool_call_id: Optional[str] = None
    is_mcp_tool: bool = False
    mcp_server_label: Optional[str] = None
    
    try:
        async for chunk in chat_stream:
            # ğŸ”´ æ£€æŸ¥æ˜¯å¦éœ€è¦å–æ¶ˆï¼ˆæ–°è½¬å†™äº‹ä»¶åˆ°æ¥ï¼‰
            if session.is_cancel_requested():
                logger.info("Chat stream cancelled due to new transcription")
                result.was_cancelled = True
                break
            
            delta = chunk.choices[0].delta
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if delta.tool_calls:
                tool_call = delta.tool_calls[0]
                function = tool_call.function
                
                # é¦–æ¬¡å‡ºç°å·¥å…·è°ƒç”¨åç§°ï¼Œåˆ¤æ–­æ˜¯å¦ä¸º MCP å·¥å…·å¹¶åˆ›å»ºå¯¹åº”ä¸Šä¸‹æ–‡
                if function.name:
                    tool_name = function.name
                    tool_call_id = tool_call.id
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸º MCP å·¥å…·
                    is_mcp_tool = session.is_mcp_tool(tool_name)
                    
                    if is_mcp_tool:
                        mcp_server_label = session.get_mcp_server_for_tool(tool_name)
                        mcp_ctx = McpCallResponseContext(
                            session=session,
                            name=tool_name,
                            server_label=mcp_server_label,
                            modalities=active_modalities,
                        )
                        await mcp_ctx.__aenter__()
                        if function.arguments:
                            await mcp_ctx.send_arguments_delta(function.arguments)
                    else:
                        # æ™®é€š function call
                        func_ctx = FunctionCallResponseContext(
                            session=session,
                            name=tool_name,
                            call_id=tool_call_id,
                            modalities=active_modalities,
                        )
                        await func_ctx.__aenter__()
                        if function.arguments:
                            await func_ctx.send_arguments_delta(function.arguments)
                elif function.arguments:
                    # åç»­å‚æ•°å¢é‡
                    if mcp_ctx:
                        await mcp_ctx.send_arguments_delta(function.arguments)
                    elif func_ctx:
                        await func_ctx.send_arguments_delta(function.arguments)
            
            # ğŸš€ æµå¼å‘é€æ–‡æœ¬å†…å®¹
            if delta.content:
                result.content += delta.content

                if audio_mode:
                    if audio_ctx is None:
                        if tts_inferencer is None:
                            raise RuntimeError("TTS inferencer is not configured for audio output")
                        audio_ctx = AudioResponseContext(
                            session,
                            tts_inferencer=tts_inferencer,
                            modalities=active_modalities,
                            format_type=audio_output_format_type,
                            voice=audio_output_voice,
                            speed=audio_output_speed,
                        )
                        await audio_ctx.__aenter__()
                    await audio_ctx.add_model_text_delta(delta.content)
                else:
                    # å»¶è¿Ÿåˆ›å»ºä¸Šä¸‹æ–‡ï¼Œåœ¨ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ°è¾¾æ—¶æ‰å‘é€å‰ç½®äº‹ä»¶
                    if text_ctx is None:
                        text_ctx = TextResponseContext(session, modalities=active_modalities)
                        await text_ctx.__aenter__()
                    await text_ctx.send_text_delta(delta.content)
        
        # æµç»“æŸåï¼Œå¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè®°å½•ç»“æœ
        if mcp_ctx and tool_call_id:
            # MCP å·¥å…·è°ƒç”¨ - å®Œæˆå‚æ•°å‘é€é˜¶æ®µ
            await mcp_ctx.finish_arguments()
            
            result.tool_call = ToolCallInfo(
                call_id=tool_call_id,
                name=tool_name or "",
                arguments=mcp_ctx.arguments,
                is_mcp=True,
                server_label=mcp_server_label,
                mcp_ctx=mcp_ctx,  # ä¼ é€’ä¸Šä¸‹æ–‡ç»™ servicer
            )
            logger.info(
                f"MCP tool call detected: name={tool_name}, "
                f"server_label={mcp_server_label}, arguments={mcp_ctx.arguments}"
            )
            # æ³¨æ„ï¼šmcp_ctx ä¸åœ¨è¿™é‡Œå…³é—­ï¼Œç”± servicer åœ¨æ‰§è¡Œè°ƒç”¨åå…³é—­
        elif func_ctx and tool_call_id:
            # æ™®é€š function call
            result.tool_call = ToolCallInfo(
                call_id=tool_call_id,
                name=tool_name or "",
                arguments=func_ctx.arguments,
                is_mcp=False,
            )
            logger.info(
                f"Function call detected: name={tool_name}, call_id={tool_call_id}, "
                f"arguments={func_ctx.arguments}"
            )
        elif result.content:
            logger.info(f"Chat stream response sent: content='{result.content}'")
    
    except asyncio.CancelledError:
        # ä»»åŠ¡è¢«çœŸæ­£å–æ¶ˆï¼ˆTask.cancel()ï¼‰
        logger.info("Chat stream task was cancelled by CancelledError")
        result.was_cancelled = True
        # æ˜¾å¼å…³é—­ç”Ÿæˆå™¨ï¼Œåœæ­¢åº•å±‚ HTTP æµ
        if hasattr(chat_stream, 'aclose'):
            try:
                await chat_stream.aclose()
            except Exception as e:
                logger.debug(f"Error closing chat stream: {e}")
        raise  # é‡æ–°æŠ›å‡ºè®©è°ƒç”¨è€…çŸ¥é“ä»»åŠ¡è¢«å–æ¶ˆ
    
    finally:
        # ç¡®ä¿ä¸Šä¸‹æ–‡æ­£ç¡®å…³é—­ï¼Œå‘é€åç½®äº‹ä»¶
        audio_synthesis_error: Optional[Exception] = None
        if audio_ctx is not None:
            should_synthesize = (
                not result.was_cancelled
                and not result.has_tool_call
                and bool(result.content.strip())
            )
            if should_synthesize:
                try:
                    await audio_ctx.synthesize_audio()
                except Exception as exc:  # pragma: no cover - defensive boundary
                    audio_synthesis_error = exc
                    logger.error("Audio synthesis failed: %s", exc)

            await audio_ctx.finish(
                cancelled=result.was_cancelled,
                failed=audio_synthesis_error is not None,
                error_code="audio_synthesis_failed" if audio_synthesis_error else None,
                error_type="server_error" if audio_synthesis_error else None,
            )
            if audio_synthesis_error and hasattr(session, "writer"):
                await session.writer.send_error(
                    message=f"Audio synthesis failed: {audio_synthesis_error}",
                    error_type="server_error",
                    code="audio_synthesis_failed",
                )

        if text_ctx is not None:
            await text_ctx.finish(cancelled=result.was_cancelled)
        if func_ctx is not None:
            await func_ctx.__aexit__(None, None, None)
        # æ³¨æ„ï¼šMCP ä¸Šä¸‹æ–‡éœ€è¦åœ¨æ‰§è¡Œè°ƒç”¨åå…³é—­ï¼Œè¿™é‡Œä¸å…³é—­
        
        # ğŸ”´ å¦‚æœè¢«å–æ¶ˆï¼Œæ‰‹åŠ¨å°†éƒ¨åˆ†å†…å®¹æ·»åŠ åˆ°å†å²è®°å½•
        # æ­£å¸¸ç»“æŸæ—¶ï¼Œchat_session.get_result_record_itr ä¼šè‡ªåŠ¨å¤„ç†
        # ä½†è¢«å–æ¶ˆæ—¶æµä¸ä¼šæ­£å¸¸ç»“æŸï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ 
        if result.was_cancelled and result.content:
            from openai.types.chat import ChatCompletionMessage
            cancelled_message = ChatCompletionMessage(
                role="assistant",
                content=result.content,  # ä¿å­˜å·²ç”Ÿæˆçš„éƒ¨åˆ†å†…å®¹
                tool_calls=[],
            )
            session.chat_session.chat_history.append(cancelled_message)
            logger.info(
                f"Cancelled chat partial content saved to history: '{result.content}'"
            )
    
    return result


async def send_tool_result_response(
    session: "RealtimeSessionState",
    chat_stream: Iterable[ChatCompletionChunk],
    *,
    modalities: Optional[list[str]] = None,
    tts_inferencer: Optional["TTSInferencer"] = None,
    audio_output_format_type: str = "audio/pcm",
    audio_output_voice: str = "alloy",
    audio_output_speed: float = 1.0,
):
    """
    å‘é€å·¥å…·è°ƒç”¨ç»“æœåçš„å“åº”æµã€‚
    ä½¿ç”¨ä¸ä¸»å¯¹è¯ä¸€è‡´çš„å“åº”ä¸Šä¸‹æ–‡å‘é€å®Œæ•´äº‹ä»¶åºåˆ—ã€‚
    """
    result = await process_chat_stream(
        session=session,
        chat_stream=chat_stream,
        modalities=modalities,
        tts_inferencer=tts_inferencer,
        audio_output_format_type=audio_output_format_type,
        audio_output_voice=audio_output_voice,
        audio_output_speed=audio_output_speed,
    )

    logger.info("Tool result response sent: content='%s'", result.content)


async def send_text_response(session: "RealtimeSessionState", content: str):
    """å‘é€çº¯æ–‡æœ¬å“åº”ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    async with TextResponseContext(session) as ctx:
        await ctx.send_text_delta(content)


async def send_chat_stream_response(
    session: "RealtimeSessionState",
    response_chunk: Iterable[str],
):
    """å‘é€æµå¼èŠå¤©å“åº”ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    async with TextResponseContext(session) as ctx:
        async for chunk in response_chunk:
            await ctx.send_text_delta(chunk)
